{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do something with these tweets we scraped. Text mining is a broad field with many practical applications in media and marketing - we will be just scratching the surface in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweets 0 to 100\n",
      "Getting tweets 100 to 200\n",
      "Getting tweets 200 to 300\n",
      "Getting tweets 300 to 400\n",
      "Getting tweets 400 to 500\n",
      "Getting tweets 500 to 600\n",
      "Getting tweets 600 to 700\n",
      "Getting tweets 700 to 800\n",
      "Getting tweets 800 to 900\n",
      "Getting tweets 900 to 1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import twitter_helpers.authentication as twit_auth\n",
    "from twitter_helpers.scraping import scrape_tweets\n",
    "\n",
    "twitter_api = twit_auth.authenticate_twitter()\n",
    "dat = scrape_tweets(\"Squirrel\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>838635622277517312</td>\n",
       "      <td>0</td>\n",
       "      <td>@RuthieConnell I see moose but where is squirrel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>838635447588798464</td>\n",
       "      <td>5867</td>\n",
       "      <td>RT @crackcokaine: This crackhead got a squirre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>838635406652555264</td>\n",
       "      <td>0</td>\n",
       "      <td>I liked a @YouTube video from @theserioussquid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>838635371575431168</td>\n",
       "      <td>5867</td>\n",
       "      <td>RT @crackcokaine: This crackhead got a squirre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>838635326163693568</td>\n",
       "      <td>8</td>\n",
       "      <td>RT @julia_zemiro: Absolutely over the moon (se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  retweet_count  \\\n",
       "0  838635622277517312              0   \n",
       "1  838635447588798464           5867   \n",
       "2  838635406652555264              0   \n",
       "3  838635371575431168           5867   \n",
       "4  838635326163693568              8   \n",
       "\n",
       "                                                text  \n",
       "0   @RuthieConnell I see moose but where is squirrel  \n",
       "1  RT @crackcokaine: This crackhead got a squirre...  \n",
       "2  I liked a @YouTube video from @theserioussquid...  \n",
       "3  RT @crackcokaine: This crackhead got a squirre...  \n",
       "4  RT @julia_zemiro: Absolutely over the moon (se...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(dat['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat['tfidf'] = list(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '030517',\n",
       " '03kaoygk3n',\n",
       " '0bmfauwuqj',\n",
       " '0feindtyrg',\n",
       " '0k39kfiweg',\n",
       " '0mx3nd4h',\n",
       " '0utofbeta',\n",
       " '10',\n",
       " '100g',\n",
       " '10m',\n",
       " '13',\n",
       " '15',\n",
       " '150th',\n",
       " '16axcaipz2',\n",
       " '17',\n",
       " '17fcpawwjm',\n",
       " '1989',\n",
       " '19th',\n",
       " '1mxkeflgyc',\n",
       " '1w0irfdz2j',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2016',\n",
       " '2017mmm',\n",
       " '21st',\n",
       " '2399',\n",
       " '278994th',\n",
       " '2x',\n",
       " '30',\n",
       " '31',\n",
       " '36gxh99gew',\n",
       " '370',\n",
       " '3fy63pfndm',\n",
       " '3gf3pnhdmc',\n",
       " '3jrcpyi4zn',\n",
       " '3lb',\n",
       " '43',\n",
       " '45',\n",
       " '47x',\n",
       " '4dvhstqjci',\n",
       " '4nmy8gggl7',\n",
       " '50p',\n",
       " '528ewtjtwb',\n",
       " '5an5bgzi2p',\n",
       " '5befkn59xj',\n",
       " '5jeighhtl5',\n",
       " '5jeqytxlcu',\n",
       " '5kuip6wfwd',\n",
       " '64',\n",
       " '69760',\n",
       " '6rgrteoxpl',\n",
       " '6vpuykodvm',\n",
       " '72',\n",
       " '723',\n",
       " '75vg6aqq94',\n",
       " '77be6lzr1z',\n",
       " '7a7dwqbfpy',\n",
       " '7nsvr6f7we',\n",
       " '7pm',\n",
       " '7r6tavw4nk',\n",
       " '7vzc2llnwj',\n",
       " '7ymm0ezg7n',\n",
       " '86oxgnjqfe',\n",
       " '8bg4s7u7zj',\n",
       " '8byvejw5g8',\n",
       " '8jriv2bza5',\n",
       " '8oxxtcoona',\n",
       " '8wjdcft5w3',\n",
       " '8wqol50qfn',\n",
       " '8xcdzatdjy',\n",
       " '911',\n",
       " '98crd4hzfg',\n",
       " '99ioeqf31s',\n",
       " '9e8be3eiks',\n",
       " '9exbreryb3',\n",
       " '9jtxfx6pl0',\n",
       " '9lmea17nst',\n",
       " '9otwowrv89',\n",
       " '9ssrg6l3tp',\n",
       " '__clayshon',\n",
       " '_alexhirsch',\n",
       " '_angieveronica',\n",
       " '_bootsiebills',\n",
       " '_h_will_',\n",
       " 'ab',\n",
       " 'abandoned',\n",
       " 'abc',\n",
       " 'abcnews',\n",
       " 'abcpolitics',\n",
       " 'abert',\n",
       " 'able',\n",
       " 'about',\n",
       " 'absolutely',\n",
       " 'accidentally',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accoutrements',\n",
       " 'accurate',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acrylic',\n",
       " 'act',\n",
       " 'actual',\n",
       " 'add',\n",
       " 'addition',\n",
       " 'address',\n",
       " 'adjuqdgxss',\n",
       " 'adopted',\n",
       " 'adorable',\n",
       " 'adult',\n",
       " 'adventure',\n",
       " 'advice',\n",
       " 'af',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agenda',\n",
       " 'ago',\n",
       " 'ahead',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'akayla',\n",
       " 'akon',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'albino',\n",
       " 'aldub',\n",
       " 'aldubxdtbyaparisyon',\n",
       " 'alexandra',\n",
       " 'alexjdsmith',\n",
       " 'alice',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allwork',\n",
       " 'almost',\n",
       " 'aloapsdtii',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'always',\n",
       " 'alxvdqblen',\n",
       " 'am',\n",
       " 'amandawidgay',\n",
       " 'amazeballs',\n",
       " 'amazing',\n",
       " 'amazingsquirrel',\n",
       " 'amazlngnature',\n",
       " 'amazon',\n",
       " 'amberandstuff',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'anchor_rajesh',\n",
       " 'and',\n",
       " 'andymilonakis',\n",
       " 'animal',\n",
       " 'animallands',\n",
       " 'animals',\n",
       " 'animalsedits',\n",
       " 'animalwelfare',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'ann',\n",
       " 'annebeck58',\n",
       " 'anniversary',\n",
       " 'annoy',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'antelope',\n",
       " 'anticipated',\n",
       " 'antique',\n",
       " 'anxiety',\n",
       " 'any',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'app',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'appliances',\n",
       " 'appreciation',\n",
       " 'apprentice',\n",
       " 'aprilbaaybe',\n",
       " 'aqd7qm3agk',\n",
       " 'aqjo8aa2bn',\n",
       " 'aqqtismn08',\n",
       " 'are',\n",
       " 'area',\n",
       " 'aren',\n",
       " 'arm',\n",
       " 'around',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'as',\n",
       " 'asf',\n",
       " 'ashhh_renae',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'ass',\n",
       " 'assault',\n",
       " 'assignment',\n",
       " 'assignments',\n",
       " 'asvpxash',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'atlantic',\n",
       " 'attempting',\n",
       " 'attention',\n",
       " 'attic',\n",
       " 'atxstoryboards',\n",
       " 'au',\n",
       " 'auction',\n",
       " 'audreywahl',\n",
       " 'ausnavy',\n",
       " 'aussie',\n",
       " 'australian_navy',\n",
       " 'automobile',\n",
       " 'autumn',\n",
       " 'avenger',\n",
       " 'avengers',\n",
       " 'average',\n",
       " 'avocado',\n",
       " 'awaited',\n",
       " 'award',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awful',\n",
       " 'awwcuteness',\n",
       " 'awwww',\n",
       " 'axrvliunpd',\n",
       " 'b2ppqn0q3g',\n",
       " 'b8bpctzbt0',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'babyshower',\n",
       " 'back',\n",
       " 'background',\n",
       " 'backpack',\n",
       " 'backstabbed',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badgermbb',\n",
       " 'badgers',\n",
       " 'bag',\n",
       " 'bait',\n",
       " 'balloupe',\n",
       " 'balls',\n",
       " 'bamboo',\n",
       " 'ban',\n",
       " 'bangtanboystfln',\n",
       " 'bank',\n",
       " 'bannimg',\n",
       " 'barack',\n",
       " 'barbara',\n",
       " 'barely',\n",
       " 'bartok526',\n",
       " 'based',\n",
       " 'basilisk',\n",
       " 'baskulqvv9',\n",
       " 'batman',\n",
       " 'battle',\n",
       " 'bayonet',\n",
       " 'bc',\n",
       " 'be',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beatrix',\n",
       " 'beautiful',\n",
       " 'beaver',\n",
       " 'because',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'beerbeauty_',\n",
       " 'before',\n",
       " 'beg',\n",
       " 'behind',\n",
       " 'bein',\n",
       " 'being',\n",
       " 'belated',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'benfobrien',\n",
       " 'berlin',\n",
       " 'bernie',\n",
       " 'berries',\n",
       " 'best',\n",
       " 'bestearthpix',\n",
       " 'bestofmelbourne',\n",
       " 'bet',\n",
       " 'bethlauzier',\n",
       " 'bets',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bigsquirrei',\n",
       " 'bigsquirrel2020',\n",
       " 'bigsurcowboy',\n",
       " 'bikwojl54s',\n",
       " 'billy',\n",
       " 'billyjyes',\n",
       " 'binge',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birdsbasement',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitchhhh',\n",
       " 'bites',\n",
       " 'bits',\n",
       " 'black',\n",
       " 'blairmcdougall',\n",
       " 'blame',\n",
       " 'ble7kf3zqm',\n",
       " 'bleflarjackson',\n",
       " 'blind',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'bm7fruh06c',\n",
       " 'bob',\n",
       " 'bomb',\n",
       " 'book',\n",
       " 'bookbuzzr',\n",
       " 'books',\n",
       " 'borat',\n",
       " 'bored',\n",
       " 'bot',\n",
       " 'both',\n",
       " 'bought',\n",
       " 'bourdain',\n",
       " 'bout',\n",
       " 'boy',\n",
       " 'bracket',\n",
       " 'brain',\n",
       " 'brains',\n",
       " 'brandon',\n",
       " 'brandon_gross',\n",
       " 'brau',\n",
       " 'bread',\n",
       " 'break',\n",
       " 'breaking',\n",
       " 'breath',\n",
       " 'breathofthewild',\n",
       " 'breeze',\n",
       " 'breitbartnews',\n",
       " 'brethren',\n",
       " 'brew',\n",
       " 'brianstelter',\n",
       " 'bribe',\n",
       " 'brightened',\n",
       " 'brilliant',\n",
       " 'brilliantorange',\n",
       " 'bring',\n",
       " 'bro',\n",
       " 'brob3rts',\n",
       " 'broke',\n",
       " 'brown',\n",
       " 'brunch',\n",
       " 'brunomars',\n",
       " 'brush',\n",
       " 'bsmith',\n",
       " 'bts',\n",
       " 'btsartmy',\n",
       " 'btsfanart',\n",
       " 'buck_lj',\n",
       " 'bud',\n",
       " 'bulbs',\n",
       " 'bullshit',\n",
       " 'bunch',\n",
       " 'bussinesswise',\n",
       " 'buster',\n",
       " 'but',\n",
       " 'butter',\n",
       " 'buttt',\n",
       " 'buying',\n",
       " 'bvvbyliyaah1',\n",
       " 'bwogue',\n",
       " 'bx8tehvpww',\n",
       " 'by',\n",
       " 'c0nvey',\n",
       " 'c5o3xa5rad',\n",
       " 'c6colgcskh',\n",
       " 'cached',\n",
       " 'cage',\n",
       " 'calebalarsen4',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calls',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'camille',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'cancelled',\n",
       " 'candace',\n",
       " 'candiqueen',\n",
       " 'cannonball',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'captures',\n",
       " 'car',\n",
       " 'carafnparrish',\n",
       " 'card',\n",
       " 'care',\n",
       " 'cared',\n",
       " 'carol',\n",
       " 'cars',\n",
       " 'carsonlanelle',\n",
       " 'cartooning',\n",
       " 'cashay_baabyy',\n",
       " 'cashmeouside',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catwinkers',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'caused',\n",
       " 'causeweregamerz',\n",
       " 'cbs4indy',\n",
       " 'cbuzzclaire',\n",
       " 'cdd6qq3puh',\n",
       " 'cduojl7x8c',\n",
       " 'celebrating',\n",
       " 'center',\n",
       " 'centralpark',\n",
       " 'century',\n",
       " 'cerisenn',\n",
       " 'chabaybay14',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'chant',\n",
       " 'charm',\n",
       " 'chasing',\n",
       " 'chawing',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'checking',\n",
       " 'cheeks',\n",
       " 'cheeto',\n",
       " 'chelle',\n",
       " 'chestnut',\n",
       " 'chew',\n",
       " 'chewed',\n",
       " 'chicks',\n",
       " 'chico',\n",
       " 'chillin',\n",
       " 'chilling',\n",
       " 'china',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'chipmunk',\n",
       " 'chips',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choking',\n",
       " 'christine',\n",
       " 'christmas',\n",
       " 'ci5kkr7xzp',\n",
       " 'ciaspygirl',\n",
       " 'cigarette',\n",
       " 'cincin1992',\n",
       " 'cindyklippenstein',\n",
       " 'cinema',\n",
       " 'cipcqqfezj',\n",
       " 'cl',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clue',\n",
       " 'cnn',\n",
       " 'co',\n",
       " 'code',\n",
       " 'code_squirrel',\n",
       " 'coffee',\n",
       " 'coin',\n",
       " 'coins',\n",
       " 'cole',\n",
       " 'colossal',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comics',\n",
       " 'coming',\n",
       " 'comments',\n",
       " 'companion',\n",
       " 'compass',\n",
       " 'complete',\n",
       " 'confession',\n",
       " 'confirm',\n",
       " 'conman',\n",
       " 'conoca',\n",
       " 'conservation',\n",
       " 'consider',\n",
       " 'continue',\n",
       " 'continues',\n",
       " 'control',\n",
       " 'conversation',\n",
       " 'convolver',\n",
       " 'cool',\n",
       " 'coolest',\n",
       " 'coolestlifehack',\n",
       " 'cooper',\n",
       " 'coox7ib9xc',\n",
       " 'cops',\n",
       " 'coreymotley',\n",
       " 'corpse_tv',\n",
       " 'correct',\n",
       " 'corrupt',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'coulda',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'courtesy',\n",
       " 'courtneyscoffs',\n",
       " 'covering',\n",
       " 'crackcokaine',\n",
       " 'crackhead',\n",
       " 'crackheadhumor',\n",
       " 'craft',\n",
       " 'crankdatholly',\n",
       " 'crawled',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'credible',\n",
       " 'crochet',\n",
       " 'crow',\n",
       " 'crows',\n",
       " 'crying',\n",
       " 'cute',\n",
       " 'cuteanimals',\n",
       " 'cuteness',\n",
       " 'cuter',\n",
       " 'cutest',\n",
       " 'cutest_anlmals',\n",
       " 'cutie',\n",
       " 'cv5iot1rsa',\n",
       " 'cyborg',\n",
       " 'cycle',\n",
       " 'cycles',\n",
       " 'cyclone',\n",
       " 'dad',\n",
       " 'daisies',\n",
       " 'dale',\n",
       " 'daltonmiller56',\n",
       " 'damage',\n",
       " 'damaging',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'darwinism',\n",
       " 'dastardly',\n",
       " 'davidschupick',\n",
       " 'dawg',\n",
       " 'dawnsnarks',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'debilitating',\n",
       " 'definitely',\n",
       " 'deflections',\n",
       " 'delightfully',\n",
       " 'delivered',\n",
       " 'demanding',\n",
       " 'denzel',\n",
       " 'depends',\n",
       " 'deranged',\n",
       " 'described',\n",
       " 'description',\n",
       " 'desert',\n",
       " 'desertstylite',\n",
       " 'despite',\n",
       " 'destination',\n",
       " 'destroy',\n",
       " 'destructive',\n",
       " 'details',\n",
       " 'detroit',\n",
       " 'devil',\n",
       " 'dgne2rb29h',\n",
       " 'dgngmulmg8',\n",
       " 'dick',\n",
       " 'dickface',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'die',\n",
       " 'died',\n",
       " 'difference',\n",
       " 'different',\n",
       " 'digital',\n",
       " 'dimmable',\n",
       " 'dirtbag',\n",
       " 'disappears',\n",
       " 'disney',\n",
       " 'distract',\n",
       " 'distracted',\n",
       " 'distraction',\n",
       " 'divert',\n",
       " 'diya',\n",
       " 'dj',\n",
       " 'djois2003',\n",
       " 'dmmwujnnpe',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'dog',\n",
       " 'doggy',\n",
       " 'doin',\n",
       " 'doing',\n",
       " 'doll',\n",
       " 'domesticate',\n",
       " 'domesticated',\n",
       " 'don',\n",
       " 'donald',\n",
       " 'donkeykoenig',\n",
       " 'dont',\n",
       " 'doomed',\n",
       " 'door',\n",
       " 'doormen',\n",
       " 'doors',\n",
       " 'doug',\n",
       " 'down',\n",
       " 'download',\n",
       " 'dr_davyyy',\n",
       " 'drank',\n",
       " 'dream',\n",
       " 'dreamingpitbull',\n",
       " 'dreams',\n",
       " 'dreamwords',\n",
       " 'drinks',\n",
       " 'dripping',\n",
       " 'drunk',\n",
       " 'duck',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'dumpster',\n",
       " 'dumptrump33',\n",
       " 'dwarf',\n",
       " 'dwindle',\n",
       " 'dylan',\n",
       " 'dylanw',\n",
       " 'dyphylline',\n",
       " 'e1xlikqsng',\n",
       " 'eager',\n",
       " 'ears',\n",
       " 'easily',\n",
       " 'easter',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'ebay',\n",
       " 'edison',\n",
       " 'effemwarner',\n",
       " 'effort',\n",
       " 'ei2kbldfhv',\n",
       " 'either',\n",
       " 'ej1avqrzjr',\n",
       " 'ejsfehbgwg',\n",
       " 'electrocuted',\n",
       " 'electronica',\n",
       " 'elysebartkus',\n",
       " 'emoji',\n",
       " 'emojis',\n",
       " 'emotion',\n",
       " 'emotionlessari',\n",
       " 'emtijoaa',\n",
       " 'encrypted',\n",
       " 'end',\n",
       " 'endad39u0l',\n",
       " 'ended',\n",
       " 'ending',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'entire',\n",
       " 'epfg2klz2x',\n",
       " 'eqw9znhwpf',\n",
       " 'ericafails',\n",
       " 'ernestvogel',\n",
       " 'escape',\n",
       " 'est',\n",
       " 'etsy',\n",
       " 'eugene',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'event',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'evolution',\n",
       " 'evolving',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'excited',\n",
       " 'exciting',\n",
       " 'exe',\n",
       " 'exhausting',\n",
       " 'expect',\n",
       " 'experiment',\n",
       " 'expert',\n",
       " 'explained',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyed',\n",
       " 'eyes',\n",
       " 'eyro9mk0kc',\n",
       " 'fabionodariph',\n",
       " 'fabulous',\n",
       " 'fabulousanimals',\n",
       " 'face',\n",
       " 'facebook',\n",
       " 'fact',\n",
       " 'facts',\n",
       " 'faisal',\n",
       " 'faithful',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'falling',\n",
       " 'falynndenae',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fanatics',\n",
       " 'fantasy',\n",
       " 'fargo',\n",
       " 'fascinatingpics',\n",
       " 'fast',\n",
       " 'fattest',\n",
       " 'favorite',\n",
       " 'favourite',\n",
       " 'faze_nikoo',\n",
       " 'feather',\n",
       " 'federal',\n",
       " 'feed',\n",
       " 'feeder',\n",
       " 'feeders',\n",
       " 'feeding',\n",
       " 'feeguwop',\n",
       " 'feel',\n",
       " 'feels',\n",
       " 'femaletexts',\n",
       " 'few',\n",
       " 'ffrostey',\n",
       " 'fiction',\n",
       " 'fight',\n",
       " 'fighting',\n",
       " 'figure',\n",
       " 'figurine',\n",
       " 'figuring',\n",
       " 'filament',\n",
       " 'final',\n",
       " 'finallevel',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'finds',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'fireplace',\n",
       " 'firing',\n",
       " 'first',\n",
       " 'fisherspeaks',\n",
       " 'fishnet',\n",
       " 'fixuglwa49',\n",
       " 'fl',\n",
       " 'fleet',\n",
       " 'fletcher',\n",
       " 'flex_mkii',\n",
       " 'flintstones',\n",
       " 'flip',\n",
       " 'flippity',\n",
       " 'flop',\n",
       " 'fly',\n",
       " 'flying',\n",
       " 'flyingsquirrel',\n",
       " 'flyyy',\n",
       " 'fmjpqpekds',\n",
       " 'fnh8z2soeq',\n",
       " 'fnkvd0l2oh',\n",
       " 'fo',\n",
       " 'foamy',\n",
       " 'focus',\n",
       " 'folkmanis',\n",
       " 'folks',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'followme',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'footprint',\n",
       " 'for',\n",
       " 'force',\n",
       " 'forest',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'fornadine',\n",
       " 'fortune',\n",
       " 'found',\n",
       " 'fox',\n",
       " 'foxvalleynutrition',\n",
       " 'fran_wils',\n",
       " 'franc',\n",
       " 'franchemartinxo',\n",
       " 'freaks',\n",
       " 'free',\n",
       " 'french',\n",
       " 'freshbuzz',\n",
       " 'fridge',\n",
       " 'friend',\n",
       " 'friends',\n",
       " 'frigates',\n",
       " 'frog',\n",
       " 'from',\n",
       " 'front',\n",
       " 'frosty_squirrel',\n",
       " 'fry',\n",
       " 'ftpokvt3mi',\n",
       " 'fuaffrmvua',\n",
       " 'fucc',\n",
       " 'fuck',\n",
       " 'fuckin',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'fun',\n",
       " 'funeral',\n",
       " 'funny',\n",
       " 'fur',\n",
       " 'furbabies',\n",
       " 'future',\n",
       " 'fxhdsm9ocz',\n",
       " 'fxsql',\n",
       " 'g4nz5zcclk',\n",
       " 'gabehamilton38',\n",
       " 'game',\n",
       " 'games',\n",
       " 'gander',\n",
       " 'garage',\n",
       " 'gardener',\n",
       " 'gary',\n",
       " 'gate1ujccq',\n",
       " 'gather',\n",
       " 'gbzffwmky2',\n",
       " 'geographic',\n",
       " 'gerbil',\n",
       " 'germans',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'ggdzxgs8ra',\n",
       " 'giant',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'girlfriend',\n",
       " 'girlposts',\n",
       " 'girls',\n",
       " 'giveaway',\n",
       " 'giving',\n",
       " 'gla1ve_csgo',\n",
       " 'glass',\n",
       " 'glider',\n",
       " 'globetrotters',\n",
       " 'glorialaw5',\n",
       " 'glove',\n",
       " 'gmvxjugo8i',\n",
       " 'gnarly',\n",
       " 'go',\n",
       " 'goals',\n",
       " 'going',\n",
       " 'goldberg',\n",
       " 'gonna',\n",
       " 'goobeak',\n",
       " 'good',\n",
       " 'goodbye',\n",
       " 'google',\n",
       " 'gopalkri',\n",
       " 'gorddownie',\n",
       " 'gordonramsay',\n",
       " 'gorgeous',\n",
       " 'gosh',\n",
       " 'gossip',\n",
       " 'got',\n",
       " 'gotta',\n",
       " 'govhowarddean',\n",
       " 'gpa',\n",
       " 'gpbspq7pvr',\n",
       " 'grad',\n",
       " 'grape',\n",
       " 'graphic',\n",
       " 'grazing',\n",
       " 'great',\n",
       " 'green',\n",
       " 'greenlight',\n",
       " 'greenteambc',\n",
       " 'gremblygunk',\n",
       " 'grenade',\n",
       " 'grey',\n",
       " 'ground',\n",
       " 'groundhog',\n",
       " 'gt',\n",
       " 'guard',\n",
       " 'guides',\n",
       " 'guinea',\n",
       " 'gulag',\n",
       " 'gun',\n",
       " 'gusss',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gvuichp5iv',\n",
       " 'gvyihzrkbn',\n",
       " 'gymgsscfv0',\n",
       " 'h0ot52qoxt',\n",
       " 'h1iilausbr',\n",
       " 'h7wyalyphr',\n",
       " 'hachacha',\n",
       " 'had',\n",
       " 'haha',\n",
       " 'hahaha',\n",
       " 'hahahaha',\n",
       " 'hail',\n",
       " 'hair',\n",
       " 'hakwy1vjeo',\n",
       " 'hall',\n",
       " 'halsey',\n",
       " 'hamah',\n",
       " 'hammer',\n",
       " 'hamster',\n",
       " 'hamstermckenzie',\n",
       " 'hand',\n",
       " 'handpuppet',\n",
       " 'hang',\n",
       " 'hangs',\n",
       " 'happened',\n",
       " 'happens',\n",
       " 'happy',\n",
       " 'harbitcrystal79',\n",
       " 'hard',\n",
       " 'harlem',\n",
       " 'has',\n",
       " 'hastings',\n",
       " 'hate',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'hazipbehgc',\n",
       " 'hbystfmaf9',\n",
       " 'hd',\n",
       " 'he',\n",
       " 'head',\n",
       " 'headed',\n",
       " 'healthyfats',\n",
       " 'hear',\n",
       " 'heard',\n",
       " 'heart',\n",
       " 'hearted',\n",
       " 'heave',\n",
       " 'heaven',\n",
       " 'heavyyyyyy',\n",
       " 'helicopter',\n",
       " 'helicopters',\n",
       " 'hell',\n",
       " 'hella',\n",
       " 'hellcat',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'hennessymamiii',\n",
       " 'her',\n",
       " 'here',\n",
       " 'herend',\n",
       " 'herself',\n",
       " 'hes',\n",
       " 'hey',\n",
       " 'hg',\n",
       " 'hi',\n",
       " 'hibernation',\n",
       " 'hide',\n",
       " 'higher',\n",
       " 'hilarychamber17',\n",
       " 'hill',\n",
       " 'hills',\n",
       " 'him',\n",
       " 'himsel',\n",
       " 'himself',\n",
       " 'hiphop',\n",
       " 'his',\n",
       " 'hit',\n",
       " 'hlvrean8zo',\n",
       " 'hmoehi3v2m',\n",
       " 'ho',\n",
       " 'hobi',\n",
       " 'hodgepodge',\n",
       " 'hogwarts',\n",
       " 'hole',\n",
       " 'holes',\n",
       " 'hollering',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>030517</th>\n",
       "      <th>03kaoygk3n</th>\n",
       "      <th>0bmfauwuqj</th>\n",
       "      <th>0feindtyrg</th>\n",
       "      <th>0k39kfiweg</th>\n",
       "      <th>0mx3nd4h</th>\n",
       "      <th>0utofbeta</th>\n",
       "      <th>10</th>\n",
       "      <th>100g</th>\n",
       "      <th>...</th>\n",
       "      <th>zimllpk9il</th>\n",
       "      <th>zippers</th>\n",
       "      <th>zippy</th>\n",
       "      <th>zjxs43u4uv</th>\n",
       "      <th>zoetv9dhaf</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zqmvij6aeo</th>\n",
       "      <th>zttcitotb3</th>\n",
       "      <th>zyh9ukabkw</th>\n",
       "      <th>zz4nikudaz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  030517  03kaoygk3n  0bmfauwuqj  0feindtyrg  0k39kfiweg  0mx3nd4h  \\\n",
       "0  0.0     0.0         0.0         0.0         0.0         0.0       0.0   \n",
       "1  0.0     0.0         0.0         0.0         0.0         0.0       0.0   \n",
       "\n",
       "   0utofbeta   10  100g     ...      zimllpk9il  zippers  zippy  zjxs43u4uv  \\\n",
       "0        0.0  0.0   0.0     ...             0.0      0.0    0.0         0.0   \n",
       "1        0.0  0.0   0.0     ...             0.0      0.0    0.0         0.0   \n",
       "\n",
       "   zoetv9dhaf  zoo  zqmvij6aeo  zttcitotb3  zyh9ukabkw  zz4nikudaz  \n",
       "0         0.0  0.0         0.0         0.0         0.0         0.0  \n",
       "1         0.0  0.0         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[2 rows x 2455 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_tf = pd.DataFrame(list(x.toarray()))\n",
    "dat_tf.columns = v.get_feature_names()\n",
    "dat_tf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>term</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>030517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>03kaoygk3n</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id        term  idf\n",
       "0            0         000  0.0\n",
       "1            0      030517  0.0\n",
       "2            0  03kaoygk3n  0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_tf = dat_tf.stack().reset_index()\n",
    "dat_tf.columns = ['document_id', 'term', 'idf']\n",
    "dat_tf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>term</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>030517</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>03kaoygk3n</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0bmfauwuqj</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0feindtyrg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0k39kfiweg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0mx3nd4h</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0utofbeta</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>100g</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document_id        term  idf\n",
       "0            0         000  0.0\n",
       "1            0      030517  0.0\n",
       "2            0  03kaoygk3n  0.0\n",
       "3            0  0bmfauwuqj  0.0\n",
       "4            0  0feindtyrg  0.0\n",
       "5            0  0k39kfiweg  0.0\n",
       "6            0    0mx3nd4h  0.0\n",
       "7            0   0utofbeta  0.0\n",
       "8            0          10  0.0\n",
       "9            0        100g  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_tf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2440852\n",
       "True       14148\n",
       "Name: is_zero, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_tf['is_zero'] = dat_tf.idf != 0\n",
    "dat_tf.is_zero.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term\n",
       "squirrel                   909\n",
       "rt                         615\n",
       "https                      584\n",
       "co                         482\n",
       "and                        292\n",
       "the                        271\n",
       "out                        206\n",
       "of                         198\n",
       "to                         190\n",
       "with                       187\n",
       "crackhead                  174\n",
       "crackcokaine               171\n",
       "his                        161\n",
       "for                        149\n",
       "from                       145\n",
       "pet                        141\n",
       "rara                       133\n",
       "6vpuykodvm                 132\n",
       "look                       125\n",
       "are                        119\n",
       "take                       118\n",
       "where                      118\n",
       "in                         118\n",
       "all                        114\n",
       "squirrels                  109\n",
       "natgeo                     107\n",
       "injured                    106\n",
       "hospital                   106\n",
       "inside                     106\n",
       "orphaned                   106\n",
       "                          ... \n",
       "needless                     1\n",
       "needed                       1\n",
       "neck                         1\n",
       "ndls61                       1\n",
       "mouth                        1\n",
       "moves                        1\n",
       "movies                       1\n",
       "mrdissent                    1\n",
       "mrs                          1\n",
       "mst                          1\n",
       "mu1xto69i6                   1\n",
       "murder                       1\n",
       "murdered                     1\n",
       "musicinloudfrequency         1\n",
       "mustache                     1\n",
       "mw0dvkipay                   1\n",
       "mxu1zmvrwa                   1\n",
       "mylzqgd89r                   1\n",
       "n4kewl6ev6                   1\n",
       "n7lno86cjd                   1\n",
       "nachtan                      1\n",
       "nadinelustre                 1\n",
       "nailed                       1\n",
       "name                         1\n",
       "nap                          1\n",
       "national                     1\n",
       "nationalcheesedoodleday      1\n",
       "naughty                      1\n",
       "nchvw58vuv                   1\n",
       "000                          1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_tf[dat_tf['is_zero']==True].groupby('term').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
