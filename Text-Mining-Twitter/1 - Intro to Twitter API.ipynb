{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Twitter official API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**   \n",
    "Great resource\n",
    "https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/ipynb/Chapter%201%20-%20Mining%20Twitter.ipynb\n",
    "\n",
    "Go to twitter dev to get an API key.\n",
    "https://dev.twitter.com/apps\n",
    "\n",
    "Must add a phone number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "from python.API_KEYS_TWITTER import *  # tell students not to put credentials on github\n",
    "auth = twitter.oauth.OAuth(ACCESS_TOKEN, ACCESS_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_api = twitter.Twitter(auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining a search result. This is a bit more complicated than requesting n=1000 tweets. Some issues:\n",
    "\n",
    "1. We need to parse the information returned, as it isn't in a neat Dataframe for us to begin analyzing.\n",
    "\n",
    "2. We need to make multiple requests to get an amount good for analysis. The limit for the Twitter API is 100 tweets per request and 180 requests per 15 minutes, which gives us 18,000 for 15 minutes.\n",
    "\n",
    "3. We need to make sure we're not getting duplicate tweets. Since tweets and tweet counts are always changing, we do this with tweet IDs. For the guide I used, see: https://dev.twitter.com/rest/public/timelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by grabbing the first result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://dev.twitter.com/rest/reference/get/search/tweets\n",
    "# general queries: https://dev.twitter.com/rest/public/search\n",
    "\n",
    "SEARCH = \"Super Bowl\"  # note that no tweets older than 1 week will be found\n",
    "search_results = twitter_api.search.tweets(q=SEARCH, count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate the structure of this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "twitter.api.TwitterDictResponse"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['statuses', 'search_metadata'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to look at the actual text of the tweets, let's grab the values instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = search_results.values()\n",
    "results = list(results)  # conver the dict_view object to a indexable list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the results (too long to print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have the results from 100 tweets. Now we can extract the text. Some experimentation gives us the structure of the `results` list.\n",
    "\n",
    "`results[0: search data or 1: metadata][tweet #][information type]`\n",
    "\n",
    "**Let's extract the text and turn it into a dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['in_reply_to_user_id', 'geo', 'metadata', 'user', 'retweeted', 'place', 'extended_entities', 'source', 'id_str', 'possibly_sensitive', 'in_reply_to_user_id_str', 'id', 'truncated', 'retweet_count', 'contributors', 'coordinates', 'in_reply_to_status_id', 'retweeted_status', 'in_reply_to_screen_name', 'lang', 'is_quote_status', 'in_reply_to_status_id_str', 'entities', 'text', 'favorited', 'favorite_count', 'created_at'])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figure out what keys are available in the python dictionary\n",
    "results[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @GMA: Retweet if you're picking the @AtlantaFalcons to win the Super Bowl! \\n\\n#SB51 #Falcons #RiseUp https://t.co/Wvm8BlrFbC\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"RT @GMA: Retweet if you're picking the @AtlantaFalcons to win the Super Bowl! \\n\\n#SB51 #Falcons #RiseUp https://t.co/Wvm8BlrFbC\",\n",
       " \"Ain't shit else to do So I might as well watch this corny shit..oh yeah #GoFalcons #RiseUp cause I hate New England â€” watching Super Bowl LI\"]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "for i in range(100):\n",
    "    tweets.append(results[0][i]['text'])\n",
    "tweets[0:2]  # take a look at the first 2 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @GMA: Retweet if you're picking the @Atlant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ain't shit else to do So I might as well watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @SoDamnTrue: I have yet to see a Super Bowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#SuperBowl livestream ðŸ‘‰Â https://t.co/CTdkHRdcDd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @SportsCenter: RT if you think the Falcons ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text\n",
       "0  RT @GMA: Retweet if you're picking the @Atlant...\n",
       "1  Ain't shit else to do So I might as well watch...\n",
       "2  RT @SoDamnTrue: I have yet to see a Super Bowl...\n",
       "3    #SuperBowl livestream ðŸ‘‰Â https://t.co/CTdkHRdcDd\n",
       "4  RT @SportsCenter: RT if you think the Falcons ..."
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dat = pd.DataFrame(pd.Series(tweets), columns=['tweet_text'])\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. We got and processed our data. Now let's grab a lot more tweets. 1000 tweets, or 10 requests, should be enough to play with."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
