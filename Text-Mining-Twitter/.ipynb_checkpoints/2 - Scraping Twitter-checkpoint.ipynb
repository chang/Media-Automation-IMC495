{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, we figured out how to interact with the Twitter API. Now we need to pull more data. 1000 tweets, or 10 requests, should be enough to play with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple pieces that go into acquiring clean data :\n",
    "\n",
    "1. We need to figure out a way to make multiple requests, but without pulling duplicate tweets.\n",
    "\n",
    "2. We need to parse the request output into a form and then put it into an form that can be analyzed - i.e. a pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tackling 1:\n",
    "\n",
    "From https://dev.twitter.com/rest/public/timelines:\n",
    "\n",
    "\"To use max_id correctly, an applicationâ€™s first request to a timeline endpoint should only specify a count. When processing this and subsequent responses, keep track of the lowest ID received. This ID should be passed as the value of the max_id parameter for the next request, which will only return Tweets with IDs lower than or equal to the value of the max_id parameter. Note that the max_id parameter is inclusive.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import pandas as pd\n",
    "import python.twitter_authentication as twit_auth\n",
    "twitter_api = twit_auth.authenticate_twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_tweets(SEARCHTERM, n):\n",
    "    \"\"\"\n",
    "    Input: a search term and a number of tweets to grab\n",
    "    Output: a pandas dataframe of the tweet text and other parameters\n",
    "    \"\"\"\n",
    "    data_types = ['id', 'text', 'retweet_count']\n",
    "    \n",
    "    tweets_dict = {}\n",
    "    tweets_dict['id'] = []\n",
    "    tweets_dict['text'] = []\n",
    "    tweets_dict['retweet_count'] = []\n",
    "      \n",
    "    # initial search without max_id parameter\n",
    "    search = twitter_api.search.tweets(q=SEARCHTERM, count=100)\n",
    "    results = list(search.values())\n",
    "    \n",
    "    for data in data_types:\n",
    "        for i in range(100):\n",
    "            tweets_dict[data].append(results[0][i][data])\n",
    "        \n",
    "    # now repeat the request to get rest of results,\n",
    "    # setting max_id to the lowest id - 1 (to avoid duplicate tweets)\n",
    "    for i in range(n // 100 - 1):\n",
    "        print('Getting tweets', (i+1)*100, 'to', (i+2)*100)\n",
    "        search = twitter_api.search.tweets(q=SEARCHTERM, \n",
    "                                           count=100, \n",
    "                                           max_id=str(min(tweets_dict['id'])-1))\n",
    "        results = list(search.values())\n",
    "\n",
    "        for data in data_types:\n",
    "            for i in range(100):\n",
    "                tweets_dict[data].append(results[0][i][data])\n",
    "    \n",
    "    # convert to a pandas dataframe and return\n",
    "    return pd.DataFrame(tweets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting tweets 100 to 200\n",
      "Getting tweets 200 to 300\n",
      "Getting tweets 300 to 400\n",
      "Getting tweets 400 to 500\n",
      "Getting tweets 500 to 600\n",
      "Getting tweets 600 to 700\n",
      "Getting tweets 700 to 800\n",
      "Getting tweets 800 to 900\n",
      "Getting tweets 900 to 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>828512897647132672</td>\n",
       "      <td>493</td>\n",
       "      <td>RT @CNN: These are some of the best ads from S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>828512897647116289</td>\n",
       "      <td>1318</td>\n",
       "      <td>RT @MartysaurusRex: Super Bowl Marty!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>828512897034752000</td>\n",
       "      <td>0</td>\n",
       "      <td>Great to another NFL team from another legal m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>828512897005260801</td>\n",
       "      <td>0</td>\n",
       "      <td>TEAM GAGA!! Watching the Super Bowl &amp;amp; supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>828512896707653633</td>\n",
       "      <td>2014</td>\n",
       "      <td>RT @korndiddy: I didn't think it was possible,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  retweet_count  \\\n",
       "0  828512897647132672            493   \n",
       "1  828512897647116289           1318   \n",
       "2  828512897034752000              0   \n",
       "3  828512897005260801              0   \n",
       "4  828512896707653633           2014   \n",
       "\n",
       "                                                text  \n",
       "0  RT @CNN: These are some of the best ads from S...  \n",
       "1             RT @MartysaurusRex: Super Bowl Marty!!  \n",
       "2  Great to another NFL team from another legal m...  \n",
       "3  TEAM GAGA!! Watching the Super Bowl &amp; supp...  \n",
       "4  RT @korndiddy: I didn't think it was possible,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = grab_tweets(SEARCHTERM=\"Super Bowl\", n=1000)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we need to validate that it was scraped correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1000\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['id'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome. We can see that we have 1000 unique tweets."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
